# -*- coding: utf-8 -*-
"""EDA_for_Sample_super_store_Task (Praveen.R).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wr2lCcZtvi5FD0mb1FATLns7BiDszoJj

## **EDA with Python Scikit Learn**
In this section we will see how the Python Scikit-Learn library for machine learning can be used to implement regression functions. We will start doing EDA for retail shop sales.

## **EDA - Exploratory Data Analysis**
Exploratory data analysis (EDA) is used by data scientists to analyze and investigate data sets and summarize their main characteristics, often employing data visualization methods. It helps determine how best to manipulate data sources to get the answers you need, making it easier for data scientists to discover patterns, spot anomalies, test a hypothesis, or check assumptions.
"""

# Commented out IPython magic to ensure Python compatibility.
# importing libraries for the prediction analysis
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
# %matplotlib inline

# importing the data set
df = pd.read_csv("/content/SampleSuperstore.csv")

print("Dataset imported successfully!")

df.head(10)

df.tail()

"""### Checking the full summary information about the dataset"""

df.info()

df.dtypes

"""### Checking the missing values"""

df.isnull().sum()

"""### Descriptive statistics about the dataset"""

df.describe().transpose()

"""### Shape of the dataset"""

df.shape

"""### Columns inside the dataset"""

df.columns

"""### Check the dataset for duplicate and dropping element"""

df.duplicated().sum()

df.drop_duplicates()

"""### Function return Series with number of distinct observations over requested axis"""

df.nunique()

"""### Finding the correlation of dataset"""

df.corr()

"""# **EDA Process**"""

# drop Country
df = df.drop(['Country'], axis = 1)

# drop Postal Code
df = df.drop(['Postal Code'], axis = 1)

"""### Comparing linear relationships between attributes using correlation coefficient generated with the help of correlation matrix

A correlation heatmap is used to list all the correlation coefficients in order to identify multicollinearity, in other words high intercorrelation above an absolute value of 0.5 between the a pair of attributes. For a pair of attributes with multicollinearity, one of them will be dropped since it would be redudant to include both of them with almost mirroring values. Another reason is to prevent overfitting.

The correlation will compare and describe the linear connection and relationship between pairs of features, through the type of correlation and its strength. A positive correlation indicates that both features will change their values in the same direction, while a negative correlation indicates that both will change in opposite directions. The larger the correlation strength, the stronger the connection and relationship.
"""

sns.heatmap(df.corr(), cmap = 'PuBu', annot = True)
plt.show()

# total Sales
round(sum(df['Sales']), 2)

# total Quantity sold
sum(df['Quantity'])

# total Profit
round(sum(df['Profit']), 2)

"""## Sales and Profit for comparisons"""

plt.figure(figsize = (15, 5))
# plot Sales and Profit for comparisons
sns.kdeplot(df['Sales'], color = 'Teal', label = 'Sales', shade = True, bw = 25)
sns.kdeplot(df['Profit'], color = 'Cornflowerblue', label = 'Profit', shade = True, bw = 25)
plt.xlim([0, 13000])
plt.ylim([0, 0.00007])
plt.ylabel('Density')
plt.xlabel('Monetary Value in USD$')
plt.title('Sales and Profit', fontsize = 20)
plt.legend(loc = 'upper right', frameon = False)
plt.show()

plt.figure(figsize = (15, 5))
# plot Sales and Profit for comparisons
sns.kdeplot(df['Sales'], color = 'Teal', label = 'Sales', shade = True, bw = 25)
sns.kdeplot(df['Profit'], color = 'Cornflowerblue', label = 'Profit', shade = True, bw = 25)
plt.xlim([13000, 22640])
plt.ylim([0, 0.00002])
plt.ylabel('Density')
plt.xlabel('Monetary Value in USD$')
plt.title('Sales and Profit', fontsize = 20)
plt.legend(loc = 'upper right', frameon = False)
plt.show()

"""Profits are mostly above sales, indicating good business. However, there are some instances where profits can be improved, such as at the USD$9,000 sales mark onwards.

The histogram density plots' highest points in the curves show the pattern of more sales transactions with less than USD$1k monetary value, and the highest profit is gained when the value is less than USD\$500.
"""

# compare linear relationships between attributes using correlation coefficient generated using
    # correlation matrix
sns.heatmap(df.corr(), cmap = 'PuBu', annot = True)
plt.show()

"""Moving on, scatter plot allows detailed observation of the overall spread and relationships between Sales and Profit for all transactions."""

fig, ax = plt.subplots(figsize = (10, 6))
# scatterplot of Sales and Profit
ax.scatter(df["Sales"] , df["Profit"], color = 'Teal')
ax.set_xlabel('Sales in USD$')
ax.set_ylabel('Profit/Loss in USD$')
plt.title('Sales and Profit', fontsize = 20)
plt.show()

sns.countplot(x=df['Segment'])

"""A state-wise analysis is carried out below."""

# total dealings for each State
df_state_dealings = df.groupby('State')['Quantity'].count().sort_values(ascending = False).plot.bar(figsize = (10, 5),color = 'Cornflowerblue')
plt.ylabel('Total Number of Dealings')
plt.xlabel('American States')
plt.title('Total State-Wise Dealings', fontsize = 20)
plt.show()

"""Superstore has the notable highest dealings in the state of California, with almost 2K of total dealings.

With a big trailing gap, New York has the second highest dealings, with around 1,125 of total dealings.

Texas is third with almost 1K of total dealings.

The states of District of Columbia, Maine, North Dakota, West Virginia, and Wyoming have comparatively negligible dealings. Even if the Superstore outlets here are newly opened, marketing strategies should be improved in these areas as well as the states with less than 100 total dealings.
"""

# total Sales for each State
df_state_sales = df.groupby('State')['Sales'].sum().sort_values(ascending = False).plot.bar(figsize = (10, 5),
                                                                                            color = 'Cornflowerblue')
plt.ylabel('Total Sales in USD$')
plt.xlabel('American States')
plt.title('Total State-Wise Sales', fontsize = 20)
plt.show()

"""The top 3 states here is same as for the previous analysis on number of dealings.

Superstore has a notable highest sales in the state of California, with over USD$450K of total sales.

With a big trailing gap, New York has the second highest sales, with over USD$300k of total sales.

With another big trailing gap, Texas is third with around USD$170K of total sales.

The states of Wyoming, South Dakota, Maine, West Virginia, and North Dakota have comparatively negligible sales. Even if the Superstore outlets here are newly opened, marketing strategies should be improved in these areas as well as the states with less than USD$20k total sales.

An analysis on state-wise profit/loss and the effect of discount on this is presented below.
"""

# total Profit for each State
df_state_profit = df.groupby('State')['Profit'].sum().sort_values(ascending = False).plot.bar(figsize = (10, 5),
                                                                                              color = 'Cornflowerblue')
plt.ylabel('Total Profit/Loss in USD$')
plt.xlabel('American States')
plt.title('Total State-Wise Profit/Loss', fontsize = 20)
plt.show()

# average Discount for each State
df_state_profit = df.groupby('State')['Discount'].mean().sort_values(ascending = False).plot.bar(figsize = (10, 5),
                                                                                                 color = 'Cornflowerblue')
plt.ylabel('Average Discount')
plt.xlabel('American States')
plt.title('Average State-Wise Discount', fontsize = 20)
plt.show()

"""Diving deeper into the profits and losses from state-wise sales, a sample of 6 states are chosen based on the categories of high profit, medium profit, low profit, low loss, medium loss, and high loss. Crucial trends are identified, starting from the collection of answers to the following targeted questions.

Which products are popular in profit-making states?

Which products are commonly purchased in loss-bearing states?

Which product categories and sub-categories can be improved in order to increase profits?
"""

def state_data_viewer(states):
# plot profit of product categories and sub-categories for the chosen states
    product_data = df.groupby(['State'])
    for state in states:
        data = product_data.get_group(state).groupby(['Category'])
        fig, ax = plt.subplots(1, 3, figsize = (30, 5))
        fig.suptitle(state, fontsize = 16)
        ax_index = 0
        # plot a chart for each category
        for category in ['Furniture', 'Office Supplies', 'Technology']:
            # plot sub-categories in each category
            category_data = data.get_group(category).groupby(['Sub-Category']).mean()
            sns.barplot(x = category_data.Profit, y = category_data.index,
                        ax = ax[ax_index], palette = 'Blues_d')
            ax[ax_index].set_ylabel(category)
            ax_index += 1
# chosen States based on profit/loss categories
states = ['California', 'Washington', 'Mississippi', 'Arizona', 'Illinois', 'Texas']
state_data_viewer(states)

"""On a regional scale, the sales and profits are analysed below."""

# average Sales and profit/loss for Region
colors = ['Cornflowerblue', 'Teal']
df_region = df.groupby(['Region'])[['Sales', 'Discount', 'Profit']].mean()
df_region.sort_values('Profit', ascending = False)[['Sales', 'Profit']].plot(kind = 'bar',
                                                                             figsize = (8, 5),
                                                                             color = colors)

plt.ylabel('Average Monetary Value in USD$')
plt.xlabel('Region')
plt.title('Average Sales and Profit/Loss for Regions', fontsize = 12)
plt.show()

"""Thank You!

"""